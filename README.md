# Azure Data Factory

This repository contains resources for mastering Azure Data Factory from scratch, specifically designed for data engineers. The repository includes pipelines, datasets, linked services, data flows, and an input file that can be used as a practical guide to understand and implement various data engineering tasks in Azure Data Factory.

## Contents

- **Pipelines**: Pre-built pipelines that demonstrate various data ingestion, transformation, and loading tasks.
- **Datasets**: Definitions of datasets used in the pipelines, representing data stored in various storage types.
- **Linked Services**: Connections to data stores and compute services that are used by the pipelines and datasets.
- **Data Flows**: Data flows that showcase complex data transformation logic and data movement operations.
- **Input File**: A comprehensive input file that serves as a guide for mastering Azure Data Factory from scratch. It covers topics such as creating and managing pipelines, datasets, linked services, and data flows.

## Getting Started

### Prerequisites

Before you start using the resources in this repository, ensure you have the following:

- An active [Azure subscription](https://azure.microsoft.com/en-us/free/).
- Access to [Azure Data Factory](https://docs.microsoft.com/en-us/azure/data-factory/introduction).
- Basic knowledge of Azure services and data engineering concepts.

### Setup Instructions

1. **Clone the repository**:
    ```bash
    git clone https://github.com/skmahaboob/AzureDataFactory.git
    cd AzureDataFactory
    ```

2. **Import into Azure Data Factory**:
    - Open your Azure Data Factory instance in the Azure portal.
    - Go to the "Author" tab and click "Import".
    - Upload the pipelines, datasets, linked services, and data flows from this repository.
    - Modify the linked services to match your Azure environment (e.g., storage account names, databases).

3. **Run the Pipelines**:
    - Trigger the pipelines to see them in action.
    - Monitor the execution in the "Monitor" tab.

4. **Use the Input File**:
    - Refer to the `Mastering_Azure_Data_Factory_Input_File.md` to understand the steps involved in setting up and running the pipelines.
    - Follow the instructions to practice and master Azure Data Factory.

## Learning Objectives

By the end of using this repository, you should be able to:

- Create and manage pipelines in Azure Data Factory.
- Define and configure datasets for various data sources.
- Establish linked services to securely connect to data stores.
- Design and implement data flows for complex data transformations.
- Monitor and debug Azure Data Factory operations.

## Contributing

Contributions are welcome! If you have any suggestions, bug fixes, or improvements, please submit a pull request or open an issue.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contact

For any questions or feedback, feel free to contact [Mahaboob](mailto:Mahaboobsheik26@gmail.com).
